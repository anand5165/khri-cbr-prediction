"""
Created on Sat Apr  6 11:36:42 2019

@author: Anand
"""

import pandas as pd
import statsmodels.api as sm
import matplotlib.pyplot as plt
import math as m
import numpy as np
import pylab 

from pandas import DataFrame
from sklearn import linear_model
from statsmodels.sandbox.regression.predstd import wls_prediction_std
from sklearn.metrics import mean_squared_error


# Reading data file
df = pd.read_csv('cbr.csv')

#Printing datafile as table
print (df)

# Plotting CBR against Plasticity index
plt.scatter(df['Plasticity index'], df['CBR Actual'], color='red')
plt.title('California Bearing Ratio Vs Plasticity index', fontsize=14)
plt.xlabel('Plasticity index (%)', fontsize=14)
plt.ylabel('California Bearing Ratio ', fontsize=14)
plt.grid(True)
z = np.polyfit(df['Plasticity index'], df['CBR Actual'], 1)
p = np.poly1d(z)
plt.plot(df['Plasticity index'],p(df['Plasticity index']),"r--")
plt.show()
 
# Plotting CBR against OMC
plt.scatter(df['OMC'], df['CBR Actual'], color='green')
plt.title('California Bearing Ratio  Vs OMC', fontsize=14)
plt.xlabel('OMC (%)', fontsize=14)
plt.ylabel('California Bearing Ratio ', fontsize=14)
plt.grid(True)
z = np.polyfit(df['OMC'], df['CBR Actual'], 1)
p = np.poly1d(z)
plt.plot(df['OMC'],p(df['OMC']),"r--")
plt.show()

# Plotting CBR against MDD
plt.scatter(df['MDD'], df['CBR Actual'], color='blue')
plt.title('California Bearing Ratio Vs MDD', fontsize=14)
plt.xlabel('MDD (T/m3)', fontsize=14)
plt.ylabel('California Bearing Ratio ', fontsize=14)
plt.grid(True)
z = np.polyfit(df['MDD'], df['CBR Actual'], 1)
p = np.poly1d(z)
plt.plot(df['MDD'],p(df['MDD']),"r--")
plt.show()

# Regression CBR = (Plasticity index,OMC,MDD)
# Y = C + C1 X1 + C2 X2 + C3 X3
X = df[['Plasticity index','OMC','MDD']] # here we have 3 variables for multiple regression. 
Y = df['CBR Actual']
 
# With sklearn Multivariate regression
regr = linear_model.LinearRegression()
regr.fit(X, Y)

# Output
print('Intercept: \n', regr.intercept_) # Value of constant C
print('Coefficients: \n', regr.coef_) # Valve of coefficient C1, C2, C3



# With statsmodels 
# Statistical info generated by statsmodels
X = sm.add_constant(X) # adding a constant
 
model = sm.OLS(Y, X).fit()
predictions = model.predict(X) 
 
print_model = model.summary()
print(print_model)
print('Parameters: ', model.params) # Give C, C1, C2, C3
print('R2: ', model.rsquared) # Give R square valve
print('Predicted values: ', model.predict()) # Give predicted values

# Finding mean square error
mse = mean_squared_error(predictions, df['CBR Actual'])
rmse = m.sqrt(mse)
print('Mean Square error: ', mse) 
print('Root mean square error: ', rmse) 


# Plotting predicted and actual valves

plt.plot(df['Slno'], df['CBR Actual'], color='blue', label='Lab CBR')
plt.plot(df['Slno'], predictions, color='red', label='Predicted CBR')
plt.title('Experimental CBR and Predicted CBR Comparison', fontsize=14)
plt.xlabel('Sample no', fontsize=14)
plt.ylabel('CBR(%) ', fontsize=14)
pylab.legend(loc='upper left')
plt.grid(True)
plt.show()

# Experimental CBR VS Predicte CBR

plt.scatter(df['CBR Actual'], predictions, color='blue')
plt.title('Experimental CBR Vs Predicred CBR', fontsize=14)
plt.xlabel('Experimental CBR', fontsize=14)
plt.ylabel('Predicred CBR ', fontsize=14)
plt.grid(True)
z = np.linspace(0, 35, 1000)
plt.plot(z, z + 0, '-r', label='Line of equality')
pylab.legend(loc='upper left')
plt.show()

################################ END MODEL #################################

# Prediction with sklearn


# For predicting new CBR from 
New_PI = 16.75 # Test value
New_OMC = 20.3 # Test value
New_MDD = 1.6 # Test value

print ('Predicted CBR: \n', regr.predict([[New_PI ,New_OMC ,New_MDD]]))





